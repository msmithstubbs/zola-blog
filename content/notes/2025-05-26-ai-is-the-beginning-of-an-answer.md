+++
title = "AI is the beginning of an answer"
[taxonomies]
tags = ["ai"]
+++

A common concern I hear from people when I mention how much I use generative AI is “But how can you trust the answer?” Well, I don’t.

I use AI to research and answer questions, but the response I get is a starting point for solving my task. I might ask ChatGPT to take list of my son’s football games and create events I can import into iCal, or research a three month forecast for the rainfall in my local area.

I can import the events into iCal but I’ll scan down the list to make sure it appears correct against the official list. This takes a bit longer, and if I’m going to check them why not enter each one myself? If I did, I’d check it anyway. I can make mistakes, too, particularly entering a list of similar, repetitive data into a calendar.

For a research task I’ll take a look a the [cited sources](https://help.openai.com/en/articles/9237897-chatgpt-search#:~:text=ChatGPT%20responses%20that%20use%20search%20will%20contain%20inline%20citations.%20If%20you%20are%20interested%20in%20exploring) in the response. Do they look credible and current? I’ll click to read a couple of them to get a better understanding of the response and understand the viewpoint for the sources.

The previous way I’d do this was a Google (or, now, [Kagi](https://kagi.com)) search. Even though Google increasingly includes answers with the search results, I generally expected I’d need to click a couple of results and read a few to find my answer.

Using an AI assistant takes this step further, but I consider the response to be the beginning of an answer, rather than the conclusion.
